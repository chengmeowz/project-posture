{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9644c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to later draw the tree\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "# Machine learning algorithms\n",
    "from sklearn.ensemble import AdaBoostRegressor #AdaBoost\n",
    "\n",
    "# Cross-validation\n",
    "'''\n",
    "GridSearchCV = Perform an optimization of the parameters. 可以保证在指定的参数范围内找到精度最高的参数\n",
    "                1. search for the best parameters for model; \n",
    "                2. automatically fit a new model on the training dataset w/ the parameters that \n",
    "                    can yield the best cross-validation performance.\n",
    "cross_val_score = to implement cross-validation in scikit-learn.\n",
    "PS: When an integer is passed to the cv parameter of cross_val_score():\n",
    "        cv=int (same as cv=StratifiedKFold(n_splits=int)) is used if the estimator is a classifier \n",
    "        and y is either binary or multiclass; In all other cases, KFold is used.\n",
    "        i.e. 写int=10会自动转换为KFold(n_splits=10),不会转换为StratifiedKFold(n_splits=10)。\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "path = os.getcwd()#get current path\n",
    "path_up1Dir = os.path.dirname(path)#go up one directory\n",
    "dataset = pd.read_excel(path_up1Dir +'/y_MVPA/y_MVPA.xlsx')#to import the preprocessed dataset into a variable\n",
    "\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5ee981",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dataset.iloc[:,5:10])\n",
    "y = dataset['aveTotalArea']\n",
    "other = pd.DataFrame(dataset.iloc[:,:4])\n",
    "# print(X, y, other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d18c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ AdaBoostRegressor Model\n",
      "Best parameter: {'learning_rate': 0.1, 'n_estimators': 30}\n",
      "Best score in r2: 0.72\n",
      "Average score in 10-Fold: \n",
      " [0.71206984 0.71576439 0.7159801  0.7145329  0.70915091 0.70944976\n",
      " 0.71038307 0.70288548 0.70322427 0.7018911  0.69916925 0.69826622\n",
      " 0.69485371 0.69733062 0.69308182 0.69723294 0.69099943 0.69839098\n",
      " 0.69792269 0.69714722 0.70434424 0.70995778 0.71283341 0.70214704\n",
      " 0.70133353 0.70283108 0.69161817 0.69979918 0.69621004 0.69247682\n",
      " 0.69315077 0.68879756 0.69925777 0.69409432 0.6913065  0.69394604\n",
      " 0.69224624 0.6862291  0.69073187 0.69014636 0.69775151 0.69855563\n",
      " 0.69463598 0.7019997  0.69179    0.68991223 0.6935703  0.6849175\n",
      " 0.69277225 0.68525181 0.68594163 0.69102926 0.68538733 0.69112965\n",
      " 0.69214723 0.69406016 0.69365476 0.6868615  0.68368344 0.68771304\n",
      " 0.71294323 0.70166534 0.70522941 0.68782871 0.68987415 0.68819289\n",
      " 0.69113067 0.69171907 0.68579936 0.68074606 0.6899449  0.68094134\n",
      " 0.68999275 0.68370557 0.68726432 0.6815186  0.68621763 0.68325316\n",
      " 0.68352179 0.68719498 0.71316623 0.70084506 0.70015911 0.69429246\n",
      " 0.68327055 0.68707508 0.6930605  0.68360136 0.69285398 0.67540783\n",
      " 0.67325385 0.68582595 0.6744666  0.69543669 0.69313742 0.68106764\n",
      " 0.68696354 0.68278179 0.68492644 0.68700094 0.70040011 0.69664986\n",
      " 0.69081985 0.68840736 0.68563918 0.68823512 0.65377588 0.69361568\n",
      " 0.69520402 0.67414022 0.67889924 0.67567739 0.65833618 0.68417592\n",
      " 0.68273779 0.68335911 0.6909653  0.67267861 0.68097625 0.68541147\n",
      " 0.70330788 0.69983052 0.69116336 0.69661539 0.68217573 0.68640345\n",
      " 0.66759405 0.66699813 0.65907704 0.6778669  0.69350894 0.66444498\n",
      " 0.68044309 0.66001783 0.67633391 0.67128409 0.68733029 0.66559582\n",
      " 0.68718649 0.67693058 0.68954833 0.69217581 0.6844383  0.6826566\n",
      " 0.68810073 0.68550923 0.67659611 0.66933399 0.67588092 0.67982205\n",
      " 0.67590428 0.67450822 0.6746568  0.67904199 0.67506932 0.68117779\n",
      " 0.66050591 0.66795571 0.67504119 0.66586796 0.69026227 0.70640048\n",
      " 0.68485178 0.6654908  0.67968927 0.67828879 0.66246228 0.67044412\n",
      " 0.66670215 0.66786893 0.6634713  0.67389597 0.6793906  0.66201258\n",
      " 0.65695963 0.65386942 0.67459444 0.65498474 0.6606691  0.67031378\n",
      " 0.69953281 0.68251736 0.6818866  0.67950391 0.6593974  0.6442575\n",
      " 0.66728542 0.65612499 0.66583842 0.65291686 0.66636607 0.69155688\n",
      " 0.66916738 0.66039231 0.66844491 0.66612284 0.65485776 0.65965306\n",
      " 0.66671357 0.67537843]\n",
      "Std score in 10-Fold: \n",
      " [0.08003554 0.07398549 0.06901811 0.06775257 0.08522197 0.08196729\n",
      " 0.08594633 0.08608849 0.08837157 0.09330416 0.0939078  0.09158818\n",
      " 0.10081572 0.09623029 0.09677095 0.09550221 0.10386931 0.09188258\n",
      " 0.09482141 0.09388882 0.09437841 0.06929172 0.08325672 0.09719689\n",
      " 0.08879119 0.09611251 0.10986311 0.08551447 0.09850121 0.09652967\n",
      " 0.10099333 0.10182447 0.10039468 0.10463892 0.10498223 0.09988598\n",
      " 0.10776356 0.10693297 0.10080285 0.1120417  0.09691001 0.07644625\n",
      " 0.09519311 0.09473103 0.10291864 0.1030524  0.10059748 0.10955993\n",
      " 0.08356238 0.10094294 0.10886522 0.09817186 0.11420071 0.10069018\n",
      " 0.10437554 0.09484325 0.09842173 0.099839   0.10697863 0.09400073\n",
      " 0.08104549 0.08251443 0.08960358 0.09708756 0.10018523 0.09990152\n",
      " 0.09628551 0.09984767 0.10885785 0.12698236 0.10056263 0.10546777\n",
      " 0.09613797 0.09425588 0.09378572 0.10780098 0.10264315 0.10945302\n",
      " 0.11113636 0.10200593 0.07132682 0.11110481 0.10042766 0.09666602\n",
      " 0.10072424 0.10044169 0.09721098 0.10470138 0.09387001 0.09285641\n",
      " 0.13643053 0.09848567 0.10570372 0.08824478 0.10255559 0.10786589\n",
      " 0.09908877 0.09680718 0.10192035 0.09804607 0.07976611 0.10409958\n",
      " 0.09565073 0.0930842  0.09648537 0.10522126 0.12811822 0.1065759\n",
      " 0.0910313  0.09931693 0.13533995 0.10106494 0.15621504 0.10959476\n",
      " 0.10906447 0.08429207 0.07845118 0.11422182 0.09752182 0.11608565\n",
      " 0.08271982 0.09012278 0.08923219 0.07907941 0.10203844 0.0894882\n",
      " 0.12460685 0.15019161 0.14388955 0.10689789 0.08399188 0.10592639\n",
      " 0.10560665 0.14666381 0.10171802 0.12009966 0.10779968 0.12270914\n",
      " 0.09557701 0.10592422 0.09746847 0.09081905 0.10189485 0.12690103\n",
      " 0.11188571 0.10192447 0.11784598 0.10182439 0.10701756 0.08011328\n",
      " 0.11488853 0.13572491 0.11985001 0.10895767 0.13338871 0.10298966\n",
      " 0.135578   0.12264434 0.09951838 0.12874799 0.08446873 0.08119024\n",
      " 0.10700325 0.13151427 0.10714216 0.10891816 0.13256668 0.12099457\n",
      " 0.11477279 0.10232853 0.10924738 0.1006459  0.10676806 0.10903134\n",
      " 0.11444432 0.12240787 0.11313861 0.1413727  0.13391289 0.1108781\n",
      " 0.08545307 0.10280204 0.11401002 0.09552862 0.12199073 0.15872015\n",
      " 0.11573038 0.12543748 0.14283978 0.12924269 0.14291053 0.09977116\n",
      " 0.12711439 0.12966108 0.11336377 0.11355299 0.14503912 0.10365308\n",
      " 0.11528242 0.10584222]\n",
      "Best estimator: AdaBoostRegressor(learning_rate=0.1, n_estimators=30)\n",
      "The Index of Best estimator: 2\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "'''\n",
    "Why AdaBoostRegressor not AdaBoostClassifier?\n",
    "    - first, there is a huge difference between classifiers and regressors. \n",
    "        Classifiers predict a set of specified labels. \n",
    "            e.g. Email Spam Detection, where to classify whether an email is either spam (1) or not spam(0) . \n",
    "        Regressors predict some value, which could be almost anything. \n",
    "            (predict real valued outputs which vary and dont require outputs predicted to be in a fixed set)\n",
    "            e.g. Predicting the runs scored by a team in a cricket match.\n",
    "    - in our case, we want to use data to predict MVPA_minutes.week from any of the four Total Area (cm²) average scores.\n",
    "    - so, we are predicting a quantity instead of a label, which means we should use regressor.\n",
    "'''\n",
    "\n",
    "'''\n",
    "The number of weak learners is controlled by the parameter n_estimators. \n",
    "The learning_rate parameter controls the contribution of the weak learners in the final combination. \n",
    "# n_estimators = The maximum number of estimators at which boosting is terminated.\n",
    "# learning_rate = Weight applied to each classifier at each boosting iteration. \n",
    "                    A higher learning rate increases the contribution of each classifier. \n",
    "'''\n",
    "\n",
    "# Set param_grid, aka the main parameters in RandomForestRegressor\n",
    "param_grid_AdaBoostRegressor = {\n",
    "    'n_estimators':np.arange(10,201,10), # 从10到200，每隔10取一个\n",
    "    'learning_rate':np.arange(0.1,1.1,0.1) # 从0.1到1，每隔0.1取一个\n",
    "}\n",
    "\n",
    "rule = 'r2'\n",
    "\n",
    "# GridSearchCV\n",
    "abr = GridSearchCV(estimator=AdaBoostRegressor(), # algorithm - AdaBoost Regressor\n",
    "                    param_grid=param_grid_AdaBoostRegressor, # specify the parameters to search over using a dict or list of dictionaries\n",
    "                    cv=10, # 10-Fold\n",
    "                    scoring=rule\n",
    "                    )\n",
    "\n",
    "# Build the model, aka training the dataset\n",
    "abr.fit(X, y.values.ravel())\n",
    "\n",
    "# Output the best parameter, cross-validation score, estimator, and the index of best estimator.\n",
    "print(\"\\n------------------ AdaBoostRegressor Model\")\n",
    "print(\"Best parameter: {}\".format(abr.best_params_))\n",
    "print(\"Best score in %s: {:.2f}\".format(abr.best_score_) %rule)\n",
    "print(\"Average score in 10-Fold: \\n\", abr.cv_results_['mean_test_score'])\n",
    "print(\"Std score in 10-Fold: \\n\", abr.cv_results_['std_test_score'])\n",
    "print(\"Best estimator: {}\".format(abr.best_estimator_))\n",
    "print(\"The Index of Best estimator: {}\".format(abr.best_index_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aff862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0339098  -0.79261576 -0.2294205  -0.28087003 -0.36918812 -0.20508435\n",
      " -0.09553414 -0.0125155   0.01815859 -0.05580265]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "机器学习不同于统计建模，有些定义不一样。sklearn这个包定义的比较奇怪而已。\n",
    "https://zhuanlan.zhihu.com/p/369330147，score接近于1越好的是R2这个指标，其他的指标是接近于0越好。把负数去掉即可。\n",
    "'''\n",
    "# 10-Fold Cross-validation to check its accuracy again\n",
    "score = cross_val_score(estimator=AdaBoostRegressor(learning_rate=0.1, n_estimators=10),\n",
    "                        X=X, y=y.values.ravel(),\n",
    "                        cv=10\n",
    "                       )\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2332a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the above optimal parameters to build new model, aka training the dataset\n",
    "abr = AdaBoostRegressor(learning_rate=0.1, n_estimators=10).fit(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2003cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " [ 0.01621825 -0.07596243 -0.10328545 -0.11278097 -0.07596243 -0.07596243\n",
      " -0.11278097 -0.11278097 -0.07596243 -0.10328545 -0.11278097  0.11871911\n",
      " -0.11278097  0.17806328  0.17780786 -0.11278097 -0.07596243 -0.11278097\n",
      " -0.07596243  3.07091314 -0.11278097  0.11871911  0.01621825 -0.07596243\n",
      " -0.10328545  0.11871911 -0.10328545 -0.11278097 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.07596243 -0.13728389  0.01621825 -0.11278097 -0.11278097\n",
      " -0.07596243 -0.11278097 -0.03593173 -0.11278097 -0.07596243  0.17780786\n",
      " -0.07596243 -0.11278097  0.11871911 -0.07596243 -0.10328545 -0.11278097\n",
      " -0.11278097  0.17780786  0.17780786 -0.11278097  0.17780786 -0.11278097\n",
      "  0.17780786  0.17780786 -0.11278097 -0.07596243 -0.11278097 -0.10328545\n",
      " -0.11278097 -0.11278097 -0.11278097 -0.11278097 -0.11278097 -0.11278097\n",
      " -0.11278097 -0.10328545 -0.11278097  0.69059381 -0.11278097 -0.11278097\n",
      "  0.01621825 -0.11278097 -0.07596243 -0.11278097 -0.07596243  0.11871911\n",
      " -0.11278097 -0.07596243 -0.11278097 -0.10328545 -0.11278097 -0.13728389\n",
      " -0.11278097 -0.07596243  0.17780786 -0.07596243 -0.11278097 -0.10328545\n",
      " -0.10328545 -0.11278097 -0.11278097 -0.11278097 -0.11278097 -0.11278097\n",
      " -0.10328545 -0.07596243  0.11871911 -0.10328545  0.04388865 -0.07596243\n",
      " -0.11278097 -0.07596243 -0.10328545 -0.11278097 -0.10328545 -0.11278097\n",
      "  0.17780786 -0.11278097 -0.11278097 -0.11278097 -0.11278097  0.01621825\n",
      " -0.11278097 -0.10328545 -0.11278097  0.17780786 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.11278097 -0.11278097 -0.10328545  0.17780786 -0.11278097\n",
      "  0.11871911 -0.07596243  0.11871911 -0.07596243 -0.23407506 -0.11278097\n",
      " -0.07596243 -0.11278097 -0.07596243 -0.11278097 -0.11278097  0.1893917\n",
      " -0.10328545  0.17780786 -0.10328545 -0.10328545 -0.11278097 -0.11278097\n",
      " -0.10328545  0.11871911 -0.11278097 -0.07596243 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.07596243 -0.11278097 -0.07596243 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.11278097 -0.07596243 -0.07596243  0.11871911 -0.10328545\n",
      " -0.07596243  0.17780786  0.11871911 -0.07596243 -0.07596243  0.17806328\n",
      "  0.17780786  0.11871911 -0.11278097 -0.10328545 -0.03593173 -0.11278097\n",
      "  0.04388865 -0.07596243 -0.11278097 -0.10328545  0.11871911 -0.03240738\n",
      " -0.07596243  0.17780786 -0.07596243  0.17780786 -0.07596243 -0.07596243\n",
      "  0.17780786  0.11871911 -0.07596243 -0.11278097 -0.07596243 -0.11278097\n",
      " -0.07596243 -0.11278097  0.17780786 -0.11278097  0.17780786 -0.07596243\n",
      " -0.11278097 -0.07596243  0.17806328 -0.10328545  0.11871911 -0.11278097\n",
      "  0.17780786  0.11871911  0.17780786 -0.07596243 -0.10328545 -0.11278097\n",
      " -0.11278097  0.11871911  0.17806328 -0.10328545 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.10328545  0.11871911 -0.10328545  0.11871911 -0.13728389\n",
      "  0.17780786 -0.11278097 -0.11278097 -0.11278097 -0.11278097 -0.11278097\n",
      " -0.11278097  0.11871911 -0.07596243 -0.07596243 -0.11278097 -0.07596243\n",
      " -0.07596243 -0.11278097 -0.11278097 -0.11278097 -0.13728389 -0.11278097\n",
      " -0.11278097 -0.13728389  0.17780786 -0.11278097 -0.07596243 -0.07596243\n",
      " -0.11278097 -0.10328545 -0.10328545 -0.11278097 -0.10328545  0.17780786\n",
      " -0.07596243  0.17806328 -0.11278097  0.17780786 -0.11278097  0.17780786\n",
      "  0.17780786 -0.11278097  0.04388865 -0.13728389 -0.07596243 -0.07596243\n",
      "  0.17780786  0.17780786 -0.11278097  0.1893917   0.11871911 -0.07596243\n",
      "  0.17780786 -0.11278097 -0.07596243 -0.11278097 -0.07596243  0.17780786\n",
      " -0.10328545 -0.07596243 -0.03593173  0.17780786  0.17780786 -0.03240738\n",
      "  0.1893917   0.04388865  0.17780786 -0.07596243 -0.07596243  0.11871911\n",
      "  0.11871911 -0.07596243 -0.07596243  0.17780786 -0.10328545  0.17806328\n",
      " -0.07596243 -0.07596243  0.11871911  0.17780786  0.17780786 -0.07596243\n",
      " -0.07596243  0.11871911 -0.03593173  0.17780786 -0.07596243 -0.11278097\n",
      " -0.11278097 -0.11278097 -0.11278097  0.17780786  0.1893917  -0.03593173\n",
      " -0.10328545 -0.11278097  0.17806328 -0.10328545 -0.10328545 -0.11278097\n",
      "  0.17780786  0.17780786 -0.10328545 -0.07596243  0.17780786 -0.11278097\n",
      "  0.11871911 -0.11278097 -0.10328545 -0.07596243 -0.11278097 -0.07596243\n",
      "  0.17780786 -0.07596243  0.17780786  0.04388865  0.17780786  0.17780786\n",
      " -0.07596243 -0.11278097 -0.07596243 -0.10328545  0.05878095  0.17780786\n",
      "  0.17780786 -0.03593173 -0.13728389 -0.10328545  0.17806328 -0.11278097\n",
      " -0.11278097 -0.10328545 -0.11278097 -0.10328545 -0.11278097 -0.10328545\n",
      "  0.11871911 -0.11278097 -0.07596243 -0.11278097 -0.11278097 -0.07596243\n",
      " -0.11278097  0.17780786  0.17780786 -0.11278097 -0.10328545  0.17780786\n",
      "  0.17780786 -0.11278097 -0.07596243 -0.07596243  0.17780786  0.17780786\n",
      " -0.07596243  0.17780786  0.11871911 -0.07596243  0.17780786 -0.11278097\n",
      " -0.07596243  0.17780786 -0.03593173 -0.07596243 -0.11278097 -0.11278097\n",
      "  0.11871911 -0.07596243  0.17780786 -0.07596243 -0.11278097 -0.03593173\n",
      " -0.07596243 -0.11278097 -0.11278097 -0.11278097 -0.11278097 -0.07596243\n",
      " -0.10328545 -0.11278097 -0.11278097 -0.11278097  0.17780786 -0.07596243\n",
      " -0.07596243  0.17780786 -0.07596243  0.17780786  0.17780786 -0.11278097\n",
      "  0.11871911 -0.07596243 -0.11278097 -0.07596243  0.11871911 -0.11278097\n",
      "  0.11871911 -0.07596243  0.01621825  0.17780786  0.04388865  0.17780786\n",
      " -0.11278097  0.11871911 -0.07596243  0.17780786 -0.07596243  0.17806328\n",
      "  0.17780786 -0.07596243 -0.07596243 -0.11278097 -0.11278097 -0.07596243\n",
      "  0.11871911 -0.10328545 -0.07596243  0.17780786  0.17780786  0.17780786\n",
      " -0.07596243 -0.07596243 -0.10328545  0.17780786 -0.10328545  0.11871911\n",
      " -0.11278097 -0.10328545  0.17780786  0.17780786 -0.11278097 -0.11278097\n",
      " -0.11278097 -0.11278097 -0.07596243 -0.11278097 -0.11278097 -0.10328545\n",
      " -0.11278097  0.17780786 -0.13728389  0.05878095 -0.11278097 -0.10328545\n",
      " -0.10328545 -0.11278097 -0.10328545  0.11871911 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.10328545 -0.10328545 -0.11278097 -0.11278097 -0.10328545\n",
      "  0.17806328 -0.03593173 -0.11278097 -0.11278097 -0.07596243 -0.10328545\n",
      "  0.1893917   0.07541835 -0.10328545 -0.07596243  0.17780786  0.17780786\n",
      " -0.11278097 -0.11278097 -0.03593173 -0.03593173  0.01621825 -0.07596243\n",
      " -0.11278097  0.17806328 -0.11278097 -0.07596243 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.07596243 -0.03593173 -0.11278097  0.01621825 -0.11278097\n",
      " -0.11278097  0.04388865 -0.11278097 -0.11278097 -0.07596243  0.01621825\n",
      " -0.11278097 -0.11278097 -0.07596243 -0.10328545  0.1893917   0.04388865\n",
      " -0.11278097 -0.11278097 -0.07596243  0.17780786  0.17780786 -0.07596243\n",
      "  0.17780786  0.04388865  0.17780786 -0.07596243  0.11871911 -0.07596243\n",
      " -0.07596243 -0.10328545  0.11871911  0.17780786 -0.11278097 -0.10328545\n",
      " -0.11278097 -0.07596243 -0.11278097 -0.07596243 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.03593173  0.11871911 -0.11278097 -0.07596243 -0.11278097\n",
      " -0.11278097 -0.11278097 -0.11278097 -0.11278097 -0.11278097 -0.11278097\n",
      "  0.11871911 -0.07596243 -0.07596243  0.17780786 -0.11278097 -0.07596243\n",
      " -0.11278097 -0.07596243  0.17806328 -0.11278097 -0.07596243 -0.07596243\n",
      " -0.11278097 -0.07596243 -0.11278097 -0.11278097 -0.07596243  0.17780786\n",
      "  1.44405834  0.17780786  1.40353171 -0.07596243 -0.07596243  0.17780786\n",
      "  0.17780786 -0.13728389 -0.11278097 -0.11278097 -0.13728389 -0.07596243\n",
      "  0.17780786 -0.07596243 -0.10328545  0.04388865  0.17780786 -0.07596243\n",
      " -0.10328545 -0.07596243  0.17780786 -0.10328545 -0.07596243 -0.07596243\n",
      " -0.13728389  0.17806328  0.17780786 -0.10328545 -0.11278097  0.17780786\n",
      " -0.11278097  0.05878095  0.1893917   4.57155644  0.28846083 -0.07596243\n",
      " -0.11278097  0.17780786  0.17780786 -0.13728389  0.11871911  0.11871911\n",
      " -0.07596243 -0.10328545 -0.11278097  0.04388865 -0.07596243  0.01621825\n",
      "  0.11871911  0.05878095  0.17780786  0.17780786 -0.11278097  0.17780786\n",
      " -0.10328545  0.01621825 -0.11278097 -0.11278097 -0.07596243 -0.11278097\n",
      " -0.11278097 -0.10328545 -0.07596243 -0.10328545 -0.07596243 -0.11278097\n",
      " -0.11278097 -0.11278097 -0.10328545 -0.10328545 -0.11278097 -0.10328545\n",
      " -0.11278097 -0.07596243  0.11871911]\n"
     ]
    }
   ],
   "source": [
    "yhat = abr.predict(X)\n",
    "print(\"Test set predictions:\\n {}\".format(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf8a60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601366798108312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "MSE(y_true=y, y_pred=yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d91c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.675784549421879"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#调用R2\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(yhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b40e86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1398633201891688"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = abr.score(X,y)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b62893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1398633201891688"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_true = y, y_pred = yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624e5753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.40425801487128565"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(abr,X,y.values.ravel(),cv=10,scoring=\"r2\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821f9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD7CAYAAAB37B+tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfrUlEQVR4nO3de3RU1f338fc3N8JdAuEaMZeCEEUivwiC5SIi4pVHrf0p62e1SlF8sGLVLtuu1aeu+tTaZbWtPquaUm21XtZPfl5aBPHKpd6DoEJCCELQQEJCgBAChFz288dMYu5EciYzJ/m81po1M2f27PMdjJ/s7DlnH3POISIi/hUV7gJERKRzFOQiIj6nIBcR8TkFuYiIzynIRUR8TkEuIuJznQ5yMzvdzDY1uh0ys6Ue1CYiIh1gXh5HbmbRwG5ginNul2cdi4hIm2I87u8C4MsThfiQIUNccnKyx7sWEeneNmzYsM85l9h8u9dBfi3w/IkaJScnk52d7fGuRUS6NzNrdZDs2ZedZhYHXAG82Mbri8ws28yyS0tLvdqtiEiP5+VRKxcDnzrn9rb2onMuyzmX6ZzLTExs8ZeBiIicJC+D/Do6MK0iIiLe8mSO3Mz6ABcCt5xsH9XV1RQWFnLs2DEvSuoW4uPjSUpKIjY2NtyliEgE8yTInXNHgMGd6aOwsJD+/fuTnJyMmXlRlq855ygrK6OwsJCUlJRwlyMiESxizuw8duwYgwcPVogHmRmDBw/WXygickIRE+SAQrwZ/XuISEd4fRy5iIg088UXX/Dii4Ejs6+//nrGjBnjaf8K8kaio6OZMGEC1dXVxMTEcMMNN7B06VKiotr+w6WgoID333+fBQsWdGGlIuInDz30EE8//TRmxrRp0xTkodS7d282bdoEQElJCQsWLKC8vJz77ruvzfcUFBTw3HPPKchFpE3V1dWMGTOGbdu2haT/iJojjyRDhw4lKyuLxx57DOccBQUFTJ8+nUmTJjFp0iTef/99AO69917Wr19PRkYGjzzySJvtRKTnqqurC+l3XhE5Il+6dGnDyNgrGRkZ/OEPf/hW70lNTaWuro6SkhKGDh3Km2++SXx8PPn5+Vx33XVkZ2fz29/+loceeogVK1YAcOTIkVbbiUjPVVdX1+4UbWdFZJBHkvplfqurq1myZAmbNm0iOjq6zT+ROtpORHqOHhnk33bkHCo7duwgOjqaoUOHct999zFs2DA+++wz6urqiI+Pb/U9jzzySIfaiUjPEeog1xx5G0pLS7n11ltZsmQJZkZ5eTkjRowgKiqKZ555htraWgD69+9PRUVFw/vaaiciPVePHJGHy9GjR8nIyGg4/PD666/nJz/5CQC33XYbV199NS+++CLnn38+ffv2BeCss84iJiaGiRMncuONN7bZTkR6LgV5F2pv9DxmzBg+//zzhucPPPAAALGxsbz99ttN2rbWTkR6Lk2tiIj4nIJcRMTnFOQiIj6nIBcR8TkFuYiIzynIRUR8zhdBbmanmNlyM9tqZrlmNtWLfrtadHQ0GRkZnHnmmVxzzTUcOXLkpPu68cYbWb58OQALFy4kJyenzbZr1qzR4loi3Zgvghz4I/C6c24cMBHI9ajfLlW/jO3mzZuJi4vj8ccfb/L6yZ6luWzZMtLT09t8XUEu0r1FfJCb2QBgBvBXAOfccefcwc72G27Tp09n+/btrFmzhvPPP58FCxYwYcIEamtrueeeezjnnHM466yzeOKJJ4DA4lpLliwhPT2dSy+9lJKSkoa+Zs2a1bAC4uuvv86kSZOYOHEiF1xwAQUFBTz++OM88sgjZGRksH79+rB8XhEJHT+c2ZkKlAJPmdlEYANwh3OusnEjM1sELAIYPXp0+z0uXQoeL2NLRgZ0cDGumpoaVq1axbx58wD4+OOP2bx5MykpKWRlZTFw4EA++eQTqqqqOO+885g7dy4bN24kLy+PL774gr1795Kens5NN93UpN/S0lJ+9KMfsW7dOlJSUti/fz8JCQnceuut9OvXj7vvvtvbzywiEcE5F9kjcgK/DCYBf3bOnQ1UAvc2b+Scy3LOZTrnMhMTEz3Yrffq11rJzMxk9OjR3HzzzQBMnjyZlJQUAN544w2efvppMjIymDJlCmVlZeTn57Nu3Tquu+46oqOjGTlyJLNnz27R/4cffsiMGTMa+kpISOi6DyciYeOHEXkhUOic+yj4fDmtBPm3EqZlbBtf6q2xxgtfOed49NFHueiii5q0Wbly5QmvAOKcC+lVQkQkMkX8HLlzrhj42sxOD266AGj7EA2fu+iii/jzn/9MdXU1ANu2baOyspIZM2bwwgsvUFtbS1FREe+++26L906dOpW1a9eyc+dOAPbv3w+0XApXRLoXP4zIAW4HnjWzOGAH8EOP+o04CxcupKCggEmTJuGcIzExkVdeeYUrr7ySd955hwkTJjB27FhmzpzZ4r2JiYlkZWVx1VVXUVdX13D5uMsvv5zvfe97vPrqqzz66KNMnz49DJ9MREIl1EFu9Zcy60qZmZmu+XUsc3NzGT9+fJfXEun07yLifxMnTiQ1NZWXX365U/2Y2QbnXGbz7TqzU0QkxCJ+jlxERNrXo4I8HNM8kUz/HiLdQ48J8vj4eMrKyhReQc45ysrKiI+PD3cpItJJfjlqpdOSkpIoLCyktLQ03KVEjPj4eJKSksJdhoh0Uo8J8tjY2IYzHkVEupMeM7UiItJdKchFRHxOQS4i4nMKchERn1OQi4j4nIJcRMTnFOQiIj6nIBcR8TkFuYiIzynIRUR8TkEuIuJzvlhrxcwKgAqgFqhp7QoWIiI9lS+CPOh859w+D/sTEekWNLUiIuJzfglyB7xhZhvMbJFHfYqIdAt+mVo5zzm3x8yGAm+a2Vbn3LrGDYIBvwhg9OjRHu1WRCTy+WJE7pzbE7wvAV4GJrfSJss5l+mcy0xMTPRityIivhDxQW5mfc2sf/1jYC6wubP9ioh0B/XXIY70qZVhwMtmVt/fc8651z3oV0TE9+rq6oAID3Ln3A5goge1iIh0O10R5Dr8UEQkhLpiakVBLiISQhqRi4j4nIJcRMTnFOQiIj6nIBcR8bn6IB9SUgIXXACffOL5PhTkIiIhVB/kvY8dg3fegQMHPN+HglxEJIQaplbqN0RHe74PBbmISAjVB3lDfCvIRUT8pUWQh+BLTwW5iEiIlJeXs2rVKgCigmd4akQuIuIjDz/8MDfddBMAA/r2DWxUkIuI+EdRURFDhgxh69atnHfuuYGNCnIREf84cOAAiYmJnH766VhwrlxBLiLiIwcOHGDQoEGBJ7W1gXsFuYiIf+zfv19BLiLiZ74bkZtZtJltNLMVXvUpIuJH1dXVrFu3jrKyMn8FOXAHkOthfyIivvTss88yc+ZMKioqSEpKCmwMYZB7cfFlzCwJuBT4v8BPvOhTRMSvDgQXxlq9ejWzZs0KbPTBiPwPwE+BOo/6ExHxrerqagCmTZtGXFxcYGMkB7mZXQaUOOc2nKDdIjPLNrPs0tLSzu5WRCRi1Qd5bGzsNxsjOciB84ArzKwAeAGYbWb/aN7IOZflnMt0zmUmJiZ6sFsRkcjUapBH8glBzrmfOeeSnHPJwLXAO865/+p0ZSIiPlVTU0NUVFTTy7tF+IhcREQaqa6ubjoah2+CPATL2Hpy1Eo959waYI2XfYqI+E27Qa4RuYhI5FOQi4j4nIJcRMTnFOQiIj6nIBcR8bnq6mpiYpodSxLCo1YU5CIiHmtzRB4VBWae709BLiLisZqamtaDPATTKqAgFxHxXJsjcgW5iIg/KMhFRHxOQS4i4nOtBnldnYJcRMQvNCIXEfE5BbmIiM+1exx5CCjIRUQ8puPIRUR8rqunVjy9sISISE928OBBHnzwQUpKShTkIiJ+4pzj1Vdf5aWXXuKZZ55hwIABZGZmNm0UyUFuZvHAOqBXsL/lzrn/09l+RUT8YvPmzVx55ZUAXHrppaxYsaJlowifI68CZjvnJgIZwDwzO9eDfkVEfKGyshKAp556ipdeeqn1RpE8InfOOeBw8Gls8OY626+IiF/U1NQAMGrUKOLi4lpvFOEjcsws2sw2ASXAm865j1pps8jMss0su7S01IvdiohEhNrgRSOi2wvqSA9y51ytcy4DSAImm9mZrbTJcs5lOucyExMTvditiEhEqB+Rt7gqUGORHuT1nHMHgTXAPC/7FRGJZL4PcjNLNLNTgo97A3OArZ3tV0TELzoU5CFc/dCL48hHAH83s2gCvxj+2znXyrE3IiLdU/0cebhG5F4ctfI5cLYHtYiI+FL9iNzXX3aKiPRkvp8jFxHp6Toc5FrGVkQkMoV7jlxBLiLSSZojFxHxOc2Ri4j4nIJcRMTnNEcuIuJzGpGLiPicvuwUEfE5jchFRHxOc+QiIj7XoamVEK5+qCAXEemkmpoaoqKiiGrvFHyNyEVEIldNTU37o3FQkIuIRLKampr258dBQS4iEslqa2sV5CIifub7EbmZnWpm75pZrpltMbM7vChMRMQvOjxHHqL1yL24ZmcNcJdz7lMz6w9sMLM3nXM5HvQtIhLxfD8id84VOec+DT6uAHKBUZ3tV0TEL7rVHLmZJRO4EPNHXvYrIhLJfD8ir2dm/YD/AZY65w618voiM8s2s+zS0lKvdisiEnYnDPK6usB9JAe5mcUSCPFnnXMvtdbGOZflnMt0zmUmJiZ6sVsRkbD78ssvKSkpOfHKhxCyIO/0l51mZsBfgVzn3MOdL0lExB/27dvHuHHjqKmp4Zxzzmm7YYiD3IsR+XnA9cBsM9sUvF3iQb8iIhEtJyeHmpoaHnjgAZYvX952wxBPrXR6RO6c+zdgHtQiIuIrn332GQDXXnsto0ePbruhD0bkIiI9ztGjR/nxj39MbGxs+yEOCnIRkUhUPxpfsmRJ+8vXQuR/2Ski0t0999xz/P3vf2+yraioCIA777zzxB0oyEVEwuvJJ5/k448/5owzzmjY1rdvX2644QaSkpJO3IGCXEQkvMrLy/nud7/LypUrT64DzZGLiIRXeXk5AwcOPPkOFOQiIuFVXl7OgAEDTr6D+iAP0TK2CnIRkRM4dOiQRuQiIn51/Phxjh07piAXEfGr8vJygM4F+Y4dgfvOTM+0Q0etiIi0ITc3l2XLlgF0bo58+XJISIALL/SosqYU5CLS49XV1fHWW29x5MiRJtsfeOABPv74Y3r16sX48eNPfgeHD8OwYRAX18lKW6cgF5Ee74033uDiiy9u9bXf/e533HXXXSc+Db89VVUhC3FQkIuI8OGHH2JmfPDBB/Tq1athe3R0NOnp6Z0LcYDjx6FRv15TkItIj1NdXU1GRgYFBQUAVFVVMW7cOKZMmRKaHWpELiLird27d5OTk8Mll1xCeno6ABdddFHodnj8OMTHh6x7BbmI9Dh79uwB4Pbbb2fevHmh32FVVcgOPQTvLr78pJmVmNlmL/oTEQml+iVoR4wY0TU7PH7cF1MrfwMeA572qD8REU8VFRWRl5cHwPr16wEYOXJk1+y8qiryv+x0zq0zs2Qv+hIRCYUrrriC7OzshucDBgxg8ODBXbNzn4zIRUQi2q5du5g/fz5Lly4F4NRTT+38YYUd1V0OPzSzRcAi4MQXKhUR8VBdXR1lZWVMmDCBWbNmdX0BIT78sMsWzXLOZTnnMp1zmYmJiV21WxERDhw4QF1dHWHLnhCPyLX6oYh0e/v27QNgyJAh4SnADyNyM3se+AA43cwKzexmL/oVEems7du38+yzzwKEZ0TunD++7HTOXedFPyIiXjl27Bi5ublcf/31bNmyBTMjNTW16wupqQmEuaZWRES+nbvuuotJkyaxZcsWfv/737N3717S0tK6vpDjxwP3kT4iFxGJNP/+97+ZMmUKv/rVr7jwwguJDtFl1k6oqipw3x0OPxQR8VpVVRU5OTksXry44ZJs9fLy8vj5z3/eNWuptEcjchGRlj7//HM2b97MbbfdRnl5OYMGDeLCZpdRmzRpEj/4wQ/CVGEjx44F7rX6oYj0dM45Lr/8cj799NOGRa+GDx/OL3/5S+bOncuZZ54Z5grbUFkZuO/bN2S7UJCLSMTLz8/n3Xff5bXXXuOCCy5g4cKFXHjhhaSnp3fdeikn6/DhwL2CXER6kpqaGr766isgcHr9jBkzKC4uJi4ujn/84x8MHz48zBV+C/Uj8n79QrYLHX4oIhHnlltuIS0tjbS0NMaMGUNxcTFZWVnk5+f7K8RBUysi0rMsW7aMO++8k8OHDzN//nyuuuoqAAYOHMgVV1yBmYW5wpNQP7USwhG5glxEukxVVRXXXXddw5eVzW3dupVRo0Zx5ZVXcvvtt3fdhR9CSSNyEekuHn74YdasWcO//vUvpk+fTu/evVu0Offcc7n33nuZOXNmGCoMEY3IRcTv3nvvPdauXcsvfvELEhISmDNnDqtXr+66izqEm0bkIuJnzjmuvvpq9u7dy8CBA8nLywvfUrLhUlkJMTGRv4ytiEhrvvrqK/bu3cuDDz5IUVFRzwtxgIqKkI7GQUEuIiGwd+9eVq5cyezZswGYOXNmq3PiPcKXX0Jyckh3oakVEfHM448/zv33309xcTG1tbUA3H333UyePDnMlXWxrVth587A408/hblzQ7o7BbmInLS8vDzuvvtuqqurAfjoo48YNmwYixcv5rLLLiMtLY3vfOc7J+7IOZgyJRB6oeZc6Ptvvo8pU0K6SwW5iHTIF198wTPPPINzjhGlpaR+/TU7duzgO4WFJI0aBcBFgwYx/+KLA1fi2bYtcOuIsjL45BO45hoYOzaEnyIo1CcWDRgA06YFvuSMiYGJE0O6O3Me/HYys3nAH4FoYJlz7rfttc/MzHTZ2dmd3q+IeGvlypUNFypu7rHHHmPDhg307tWLTceO8R2vR7b9+sGOHRCuK937gJltcM5lNt/e6RG5mUUD/w+4ECgEPjGzfzrncjrbt4h0jT179rB27VoWLFgAQC/gB8CARm3mAC8lJ5NUVQVFRfDUU3D55d4V0acP9NQvRDvJi6mVycB259wOADN7AZgPKMhFwqz+C8d6W7duZf369ZSUlFBYWMju3btJzM/nP/PzSQDeiolhypQpxJaV0Wvr1hb9ucpKmDULpk6FG24I/RSFdIgXQT4K+LrR80Kgxcy+mS0CFgGMHj3ag92KSHtefPFFrr32Wurq6kgk8CdzTPAWDST078+p8fH85/HjnBoby5GUFHr37k2f2lo45RR4+GH40Y+a9Gnx8YE5X4koXvwXae1XcovJM+dcFpAFgTlyD/Yr0rZNm6CwMNxVhFxtbS3l5eX86U9/Yu/evU1e279/Pz9MTGTOnDlMef99UuoPh6tXURG4AfzmN/T+2c+6qGrxmhdBXgic2uh5ErDHg3477tgxePPNby5yKuFRVwcbN34TDuFSWRmYv+0BooEE4FdtNThyBJ59NvD4pz+FW24JjKijo785oiImBgYO7JJ6JTS8CPJPgDFmlgLsBq4FFnjQb0s1NXD77dBs5MGnn8KuXSHZpXxLUVGBP8vDbe5cuP/+bjOHW1BQwNtvv91kW1lZGf/94ot87+qrmT17dvsn3URHw4QJmhbppjr9X9U5V2NmS4DVBAYITzrntnS6stZs3AiPPw4pKU2XhBw4EB54AC69NCS7lW9h+HAdPvYtbdy4ka+//rrV13bu3Mk777zDBx98QGlpaYvXR4wYwZK//Y1+IVwiVSKfJ7+enXMrgZVe9NWuzz4L3L/xBnTkbDGRCFBVVcWePU1nG+vq6li9ejW5ubk89thj7b5/xIgRjB07ltdee42zzz67yWtRUVE9ZzlYaZO//s7atCkwEk9NDXclIg1qa2tZtWoVh4MXECgqKuL111+nvLycvLw8jh49SlVVVavvNTOmTZvGH//4x1YDOTo6mjPOOIMYTYlIO/z10/HDHwZOe9UIRLrY4cOHKSgoYM2aNeTn57Nr1y7KysrYvn07JSUl1NXVNWk/atQoUlNT+f73v0+/fv0YP348sbGxTdqMHDmSOXPm+PM6lBJR/BXk//EfgZuIB7Zv386hQ4fIzc2lsrKSLVu2UFlZSW5ubotg3rJlCxXBo3Hi4+MZNmwYKSkpzJw5k6SkJM444wymTp0KBEbZaWlpGkVLl9FPmviOc45XXnmF4uJicnJy2py2aP6ed999lx07djQ8b65379707duXsWPHMmDAgCavzZkzh8suu4zTTjuN2bNnaxQtEUVBLhGjqqqKiooKtm3bxv79+ykoKGjyek1NDatWrWLLli3s3r0bgD59+jCwg8dAJyQkcM8999CrVy8Ahg0bxqhRo0hKSmLo0KEMHz6cuBBejkskVBTkEjZHjx7l6NGj5OTk8NZbb/HrX/+6xZRGc/3792fWrFncfPPN3HLLLQwePLghmEV6KgW5tKqmpoZDhw59q/dUVFSQn5/fMJouLi5uGDk759i5cycHDx4EAoff7dy5s8kUx6xZs7j44otJT0+nb9++jB8/vsU8c79+/YiPj+/chxPpZhTkPdD+/fvZs2cPK1eubPiyr3GgOuf48MMPKS4u7tR+YmJiSE1NbTisLiEhocnZh9dccw2JiYmkpaWRkJDA1KlTWxzZISInpiD3sUOHDrF27dqGEN63bx+7du1i/fr15OXltfqe2traFosrpaWl0adPnxbb7rjjjhbb2xMVFdUwmk5PT6dXr16acxbpAgpyH6qsrOTtt9/mL3/5CytWrGjx+oABA7j88svbvGr5aaedxuDBgzn//PNJS0vTKFjE5xTkIVBaWsqBAweAQOiuWLGi4RjkE9mzZw/FxcUUFBRQVlbWapuKioqGCwYsXryYhQsXAhAXF0d6erpO2RbpYRTk7aiqquL999+nsNm61pWVleTl5XHw4MGG45IBdu/eTXFxMZWVlS36io+P79Cxx/XHMY8bN47U1NQ23zNjxgzGjRvH6aefrhNPRHq4HpsA27dvb1gbY+vWrWRlZXHw4EFycnIa5pxramraPBwuPj6ePn36kJ6e3hCk48aNY/78+QwaNIiUlJSGED7rrLM488wzu+BTiUhP1K2C3DlHdXU1r776Kvv37wcCazavXLmSqqoqnHPs2LGjYdqjsX79+jFt2jQWLVpE3759gcCCRVOmTGH8+PFNRsZRUVGMHj2a6OjorvlgIiLt6BZB/sQTT/Dee++xevVqSkpKWryenJxMeno6AOnp6SQnJzN8+HBGjhzZ0Gb69OkMHjy4y2oWEfGKr4L8/vvv5/nnn2+yzTlHbm4uQ4cOJSUlhcWLFzN27FhmzZrVMIoeNmyYvgAUkW7LV0E+fPjwhpF1Y/PmzeM3v/mNzvgTkR7JWlsFrsNvNruGwHVfxwOTnXPZHXlfZmamy87uUFMREQkysw3Ouczm2zs737AZuApY18l+RETkJHVqasU5lwtobWYRkTDSN4AiIj53whG5mb0FDG/lpV84517t6I7MbBGwCGD06NEdLlBERNp3wiB3zs3xYkfOuSwgCwJfdnrRp4iIaGpFRMT3OhXkZnalmRUCU4HXzGy1N2WJiEhHdfaolZeBlz2qRURETkKnTgg66Z2alQK7TvLtQ4B9HpbTlfxcO/i7ftUeHn6uHSKv/tOcc4nNN4YlyDvDzLJbO7PJD/xcO/i7ftUeHn6uHfxTv77sFBHxOQW5iIjP+THIs8JdQCf4uXbwd/2qPTz8XDv4pH7fzZGLiEhTfhyRi4hII74KcjObZ2Z5ZrbdzO4Ndz3NmdmTZlZiZpsbbUswszfNLD94P6jRaz8LfpY8M7soPFU31HKqmb1rZrlmtsXM7ghuj/j6zSzezD42s8+Ctd/nl9ob1RNtZhvNbEXwuZ9qLzCzL8xsk5llB7f5on4zO8XMlpvZ1uDP/lS/1N6Ec84XNyAa+BJIBeKAz4D0cNfVrMYZwCRgc6NtvwPuDT6+F3gw+Dg9+Bl6ASnBzxYdxtpHAJOCj/sD24I1Rnz9gAH9go9jgY+Ac/1Qe6PP8BPgOWCFn35ugjUVAEOabfNF/cDfgYXBx3HAKX6pvfHNTyPyycB259wO59xx4AVgfphrasI5tw7Y32zzfAI/LATv/1ej7S8456qcczuB7QQ+Y1g454qcc58GH1cAucAofFC/CzgcfBobvDl8UDuAmSUBlwLLGm32Re3tiPj6zWwAgcHXXwGcc8edcwfxQe3N+SnIRwFfN3peGNwW6YY554ogEJbA0OD2iP08ZpYMnE1gZOuL+oNTE5uAEuBN55xvagf+APwUqGu0zS+1Q+CX5htmtiG4XDX4o/5UoBR4KjittczM+uKP2pvwU5C3dhkiPx9yE5Gfx8z6Af8DLHXOHWqvaSvbwla/c67WOZcBJAGTzezMdppHTO1mdhlQ4pzb0NG3tLIt3D835znnJgEXA//bzGa00zaS6o8hMBX6Z+fc2UAlgamUtkRS7U34KcgLgVMbPU8C9oSplm9jr5mNAAjelwS3R9znMbNYAiH+rHPupeBm39QPEPzTeA0wD3/Ufh5whZkVEJgunG1m/8AftQPgnNsTvC8hsIjeZPxRfyFQGPzrDWA5gWD3Q+1N+CnIPwHGmFmKmcUB1wL/DHNNHfFP4Ibg4xuAVxttv9bMeplZCjAG+DgM9QFgZkZgrjDXOfdwo5civn4zSzSzU4KPewNzgK34oHbn3M+cc0nOuWQCP9PvOOf+Cx/UDmBmfc2sf/1jYC6Bi7JHfP3OuWLgazM7PbjpAiAHH9TeQri/bf02N+ASAkdTfEngUnNhr6lZfc8DRUA1gd/eNwODgbeB/OB9QqP2vwh+ljzg4jDX/l0CfyZ+DmwK3i7xQ/3AWcDGYO2bgV8Gt0d87c0+xyy+OWrFF7UTmGf+LHjbUv//pY/qzwCygz87rwCD/FJ745vO7BQR8Tk/Ta2IiEgrFOQiIj6nIBcR8TkFuYiIzynIRUR8TkEuIuJzCnIREZ9TkIuI+Nz/B1Fc2f+THBRTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y = dataset['MVPA']\n",
    "sorted(y)\n",
    "plt.plot(range(len(y)),sorted(y),c=\"black\",label= \"Data\")\n",
    "plt.plot(range(len(yhat)),sorted(yhat),c=\"red\",label = \"Predict\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2345ba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zclalala/Documents/GitHub/project-posture/x_TotalArea_y_MVPA/x_TotalArea_y_MVPA_AdaBoost.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw the AdaBoost\n",
    "abr_tree = abr.estimators_[0] # Draw the first tree\n",
    "\n",
    "# Export a decision tree w/ color in DOT format.\n",
    "dot_data = tree.export_graphviz(decision_tree=abr_tree, # decision tree classifier\n",
    "                               filled=True, # True: paint nodes to indicate majority class for classification, extremity of values for regression, or purity of node for multi-output\n",
    "                               rounded=True, # True: draw node boxes with rounded corners and use Helvetica fonts instead of Times-Roman\n",
    "                               special_characters=True # True: do not ignore special characters for PostScript compatibility\n",
    "                               )\n",
    "\n",
    "# Output the graph\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(filename='x_TotalArea_y_MVPA_AdaBoost', \n",
    "            directory=path_up1Dir +'/x_TotalArea_y_MVPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df8351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
